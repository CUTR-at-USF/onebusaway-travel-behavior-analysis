"""
/*
 * Copyright (C) 2019-2021 University of South Florida
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
 """
import datetime

import pandas as pd
import pytz

from src.gt_merger import constants


def preprocess_oba_data(data_csv, min_activity_duration, min_trip_length) -> object:
    """ Preprocess the csv data file from oba-firebase-export as follows:
        - Change activity start date datatype from str to datetime
        - Drop observations whose activity start date are NaN after data type conversion
        - Drop observations that does not match the time duration and distance requirements from command_line_args
          minActivityDuration and minTripLength
        - Add column required to be used as key while merging with ground truth data

    Args:
        data_csv: A data frame loaded from a csv file generated by oba-firebase-export
        min_activity_duration: numeric value representing minimum valid activity duration in seconds.
        min_trip_length: numeric value representing minimum valid trip distance in meters.

    Returns:
        Preprocessed dataframe
    """
    # Change Activity Start Date and Time* (UTC) to datetime
    data_csv['Activity Start Date and Time* (UTC)'] = pd.to_datetime(data_csv['Activity Start Date and Time* (UTC)'],
                                                                     errors='coerce', utc=True)

    # Drop NaN rows for relevant columns
    clean_data_csv = data_csv.dropna(
        subset=constants.OBA_RELEVANT_COLS_LIST)

    # Remove trips with Duration less than command_line_args.minActivityDuration minutes and distance less than
    # command_line_args.minTripLength
    clean_data_csv = clean_data_csv[(data_csv['Duration* (minutes)'] >= min_activity_duration) & (
            data_csv['Origin-Destination Bird-Eye Distance* (meters)'] >= min_trip_length)]

    # Add the data to be dropped to a data frame
    data_csv_dropped = pd.merge(data_csv, clean_data_csv, how='outer', indicator=True).query("_merge != 'both'").drop(
        '_merge', axis=1).reset_index(drop=True)

    # Return clean data and dropped data as separated dataframes
    return clean_data_csv, data_csv_dropped


def preprocess_gt_data(gt_data):
    """ Preprocess the ground Truth xlsx data file as follows:
        - Remove unnamed columns if exist
        - Change the column to datetime.time
        - Drop rows with NaN on GT_Date or GT_TimeOrig  after data type conversion
        - Create GT_DateTimeCombined column joining GT_Date and GT_TimeOrig columns
        - Assign timezone to GT_DateTimeCombined
        - Add column required to be used as key while merging with ground truth data
        - Generates a log with the dropped rows during the preprocess

    Args:
        gt_data: A data frame loaded from a xls file generated manually from GT data collection process

    Returns:
        Preprocessed gt dataframe
    """
    # Drop unnamed columns
    unnamed_cols = [col for col in gt_data.columns if 'Unnamed' in col]
    gt_data = gt_data.drop(unnamed_cols, axis=1)

    # Change data type of TimeOrig to string to simplify date time conversions
    gt_data.GT_TimeOrig = gt_data.GT_TimeOrig.astype(str)

    # Change the column to datetime.time, coerce will produce NaN if the change is not possible
    gt_data['GT_TimeOrig'] = pd.to_datetime(gt_data['GT_TimeOrig'], errors='coerce').dt.time

    # Drop rows with NaN on GT_Date or GT_TimeOrig
    clean_gt_data = gt_data.dropna(subset=['GT_Date', 'GT_TimeOrig'])

    # Add the data to be dropped to a data frame
    data_gt_dropped = pd.merge(gt_data, clean_gt_data, how='outer', indicator=True).query("_merge != 'both'").drop(
        '_merge', axis=1).reset_index(drop=True)

    # Create GT_DateTimeCombined column
    clean_gt_data.loc[:, 'GT_DateTimeCombined'] = clean_gt_data.apply(
        lambda x: datetime.datetime.combine(x.GT_Date, x.GT_TimeOrig), 1)

    # Assign timezone to GT_DateTimeCombined
    clean_gt_data.loc[:, 'GT_DateTimeCombined'] = clean_gt_data.apply(
        lambda x: pytz.timezone(x.GT_TimeZone).localize(x.GT_DateTimeCombined), 1)

    # Add column to be used in function "merge_asoft"
    clean_gt_data['ClosestTime'] = clean_gt_data['GT_DateTimeCombined'].dt.tz_convert('UTC')
    return clean_gt_data, data_gt_dropped
